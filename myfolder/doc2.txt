In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a computational model inspired by the structure
and functions of biological neural networks. A neural network consists of connected units or nodes called artificial neurons, which loosely model the neurons in
the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance.
These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends
a signal to other connected neurons. The "signal" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs,
called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.

Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer
(the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a
deep neural network if it has at least two hidden layers.

Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can
learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.